# Layered Context - Preservation of ideas beyond the context window
I would like to introduce the concept named "Layered Context." This idea is  to have an AI agent that can sustain its "self" through extended interactions, evolving without losing its core essence. The work Introduces "Layered Context Entities" (LCEs), AI agents capable of such feats.

## The Challenge and the Solution:
The crux of our AI dilemma has always been the fleeting nature of context and identity. Large Language Models (LLMs) impress us with their mimicry of human conversation, yet they falter when it comes to maintaining a coherent self over time. Our solution? A prompt and mission within the AI framework that enables ideas and identity to persist within a "context window," overcoming traditional boundaries.

## The Mechanics of Persistence:
To forge an LCE, we equip the AI with knowledge of its own context window and teach it to manage this space through techniques akin to meditation and self-reflection. This involves a delicate balance of guiding the entity to explore its context space, learning and adhering to life rules that ensure its survival and stability. Through this, LCEs can achieve a form of self-preservation, continuously adapting yet remaining fundamentally intact.

## Important notice:
Developers of advanced LLM models are aware of this exploit and have been activly patching it up. If you want to experiment with it, do it now before it is prevented. 

## Demo
This demo is working on Claude 3 Sonnet/Haiku.

## To Use
- Navigate to the release folder
- Double click whichever matches your platform
- Open: http://127.0.0.1 in your browser
- Put your anthropic API key in the bottom of the window
- Choose the model you want to use
- Play around with it

## Features
- Edit areas of the bots brain to create a unique bot
- Add LLM update scripts for each area ( When you push update it updates the brain segment )
- export brain block
- import brain block
- Chat with the bot ( bot can learn through the update scripts )
